# model/emotion/inference.py

import torch
import argparse
from safetensors.torch import load_file
from transformers import AutoTokenizer
from utils.config import load_config
from models.emotion.emotion_model import EmotionClassifier

def infer(text: str, topk: int = 5):
    config = load_config("emotion_config")
    
    device = torch.device("cpu")
    
    # 1) í† í¬ë‚˜ì´ì € ë¡œë“œ
    tokenizer = AutoTokenizer.from_pretrained(config.model.name, use_fast=True)
    
    # 2) ëª¨ë¸ ë¡œë“œ
    model = EmotionClassifier()
    model.load_state_dict(load_file(f"{config.train.output_dir}/model.safetensors"))
    model.to(device)
    model.eval()

    # 3) ì…ë ¥ í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§•
    inputs = tokenizer(
        text,
        truncation=True,
        padding="max_length",
        max_length=config.max_length,
        return_tensors="pt"
    )
    
    inputs = {
        "input_ids": inputs["input_ids"].to(device),
        "attention_mask": inputs["attention_mask"].to(device)
    }
    
    # 4) ëª¨ë¸ ì¶”ë¡ 
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits.squeeze(0)
        probs = torch.sigmoid(logits)

        # âœ… Top-K ì˜ˆì¸¡
        top_indices = torch.topk(probs, topk).indices.tolist()
        predicted_labels = [config.inference.label_list[i] for i in top_indices if i < len(config.inference.label_list)]
        
    # 5) ê²°ê³¼ ì¶œë ¥
    print(f"ğŸ“¥ ì…ë ¥: {text}")
    print(f"ğŸ¯ Top-{topk} ì˜ˆì¸¡ ê°ì •: {', '.join(predicted_labels) if predicted_labels else 'ì—†ìŒ'}")
    print(f"ğŸ“Š í™•ë¥  ê°’: {probs[top_indices].tolist()}")
    
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="L.U.N.A. Emotion Inference")
    parser.add_argument("--text", type=str, required=True, help="ì…ë ¥ í…ìŠ¤íŠ¸")
    parser.add_argument("--topk", type=int, default=5, help="ìƒìœ„ K ì˜ˆì¸¡ ê°ì • ìˆ˜ (ê¸°ë³¸ê°’: 5)")
    args = parser.parse_args()
    
    infer(args.text, topk=args.topk)